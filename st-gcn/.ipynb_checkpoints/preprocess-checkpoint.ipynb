{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rotation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import import_ipynb\n",
    "from rotation import rotation_matrix, unit_vector, angle_between, x_rotation, y_rotation, z_rotation\n",
    "\n",
    "# for machine learning\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler, EditedNearestNeighbours, AllKNN\n",
    "\n",
    "import csv\n",
    "from csv import reader\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 3\n",
    "NUM_JOINTS = 20\n",
    "NUM_FRAMES = 16\n",
    "FILE_NAME = '../train.csv'\n",
    "test_FILE_NAME = '../test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtf = pd.read_csv(FILE_NAME, header = None)\n",
    "#dtf = dtf.set_index(dtf.columns[0])\n",
    "\n",
    "dtf = dtf.sample(frac = 1)\n",
    "X = dtf.iloc[:,:-1]\n",
    "y = dtf.iloc[:,-1]\n",
    "\n",
    "dtf_test = pd.read_csv(test_FILE_NAME, header = None)\n",
    "#dtf_test = dtf_test.set_index(dtf_test.columns[0])\n",
    "\n",
    "dtf_test = dtf_test.sample(frac = 1)\n",
    "X_test = dtf_test.iloc[:,:]\n",
    "X_test_index = dtf_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1          2         3        4         5          6    \\\n",
      "3445  3446  2.763200   1.814600   1.24620  4.35440  -5.60340   2.013300   \n",
      "3940  3941  0.078721   0.236160   0.11386  0.47092  -0.87226   0.070287   \n",
      "980    981  8.604900  77.222000 -33.38400  1.64850  80.84900 -28.205000   \n",
      "8517  8518 -0.838180   0.099734  -0.27461 -1.36490  -0.29374   0.086755   \n",
      "9377  9378  2.902900  -4.941600  -4.60230  2.22080  -1.38000  -7.522300   \n",
      "...    ...       ...        ...       ...      ...       ...        ...   \n",
      "5682  5683 -0.356610   0.238640  -0.53626 -0.56643  -0.13004  -0.790310   \n",
      "295    296  0.083236   8.326500 -12.89400  3.66380   8.36110  -2.151600   \n",
      "1304  1305  8.661800 -27.151000  45.20800  4.26740 -14.75500  49.767000   \n",
      "1989  1990 -0.195580   0.020587   0.37507 -0.19944   0.26120   0.544910   \n",
      "6192  6193 -1.321800  -0.165640   0.46260 -0.72063  -0.99252   0.301580   \n",
      "\n",
      "           7         8          9    ...      951        952      953  \\\n",
      "3445  7.651700 -17.95700   1.295000  ...   8.2669  -3.678800   1.1046   \n",
      "3940  1.329800  -1.72060  -0.297310  ...   3.7990  -0.099104   4.6509   \n",
      "980  -5.181000  83.85200 -22.850000  ...  -5.9292  30.973000   1.0612   \n",
      "8517 -2.271300  -0.99188   0.089488  ...   1.1189  -3.299400  -1.3758   \n",
      "9377  1.659600   3.86730 -13.476000  ... -19.3360  28.381000 -11.5080   \n",
      "...        ...       ...        ...  ...      ...        ...      ...   \n",
      "5682 -0.825840  -0.75211  -0.959910  ...  40.5480  12.372000  -7.9789   \n",
      "295   5.618800  10.80700   8.755200  ... -32.5890   5.246800   3.0731   \n",
      "1304 -1.542700 -13.77200  40.963000  ... -40.3340 -12.015000  58.3430   \n",
      "1989 -0.090067   0.53333   0.717320  ...  -1.1265  -2.311500   4.7864   \n",
      "6192  0.434890  -1.94480   0.155080  ...  74.9790 -24.435000  31.6230   \n",
      "\n",
      "            954       955      956      957        958        959       960  \n",
      "3445    6.38700   2.71440 -23.8900  10.0300   -2.33150 -23.775000  10.66600  \n",
      "3940   -1.29120   0.85891   1.9800   2.9654   -0.18696   0.043578   1.16250  \n",
      "980    40.90600 -17.92900  -2.8760  19.0150  -16.60300  -2.505300  17.54100  \n",
      "8517    0.42490  -0.33541  -2.8131  -1.4632    9.61140   0.621630  -3.08700  \n",
      "9377   24.37600   2.18640   4.9533  -1.3147    1.93090   6.325000 -11.18600  \n",
      "...         ...       ...      ...      ...        ...        ...       ...  \n",
      "5682   34.95100   1.93720   1.4814   4.8699    5.20780  22.655000 -36.16100  \n",
      "295    23.33000   5.29840   1.3708   7.5605  -44.06700 -12.302000  57.55600  \n",
      "1304 -134.12000  91.02600  88.0450  48.9150  110.37000  85.521000  60.07500  \n",
      "1989   -0.73791  -2.45110   2.9735   4.1952    1.01130   3.826600  -0.31009  \n",
      "6192   76.91100 -60.24700  40.3280  28.4110  -62.84300   2.384900  99.97400  \n",
      "\n",
      "[9388 rows x 961 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xyz(row):\n",
    "    skeleton_data, label = read_skeleton(row)\n",
    "    \n",
    "    data = np.zeros((NUM_FRAMES, NUM_JOINTS, NUM_FEATURES))\n",
    "    for m, i in enumerate(skeleton_data['frame_info']):\n",
    "        for n, j in enumerate(i['joint_info']):\n",
    "            feature_info = j['feature_info']\n",
    "            data[m, n, :] = [feature_info['x'], feature_info['y'], feature_info['z']]\n",
    "\n",
    "    data = data.transpose(2, 0, 1)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_skeleton(row):\n",
    "    label = row[-1]\n",
    "    #label = -1\n",
    "    skeleton_data = {}\n",
    "    skeleton_data['index'] = row[0]\n",
    "    skeleton_data['num_frame'] = NUM_FRAMES\n",
    "    skeleton_data['frame_info'] = []\n",
    "    \n",
    "    for frame in range(NUM_FRAMES):\n",
    "        offset = NUM_JOINTS * NUM_FEATURES\n",
    "        data_in_frame = row[frame*offset:(frame+1)*offset]\n",
    "        frame_info = {}\n",
    "        frame_info['num_joints'] = NUM_JOINTS\n",
    "        frame_info['joint_info'] = []\n",
    "        \n",
    "        for feature in range(NUM_JOINTS):\n",
    "            offset = NUM_FEATURES\n",
    "            data_in_joint = data_in_frame[feature*offset:(feature+1)*offset]\n",
    "            joint_info = {}\n",
    "            joint_info['num_features'] = NUM_FEATURES\n",
    "            joint_info['feature_info'] = {\n",
    "                k: float(v)\n",
    "                for k, v in zip(['x', 'y', 'z'], data_in_joint)\n",
    "            }\n",
    "            frame_info['joint_info'].append(joint_info)\n",
    "                    \n",
    "        skeleton_data['frame_info'].append(frame_info)\n",
    "    return skeleton_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation(data):\n",
    "    N, C, T, V, M = data.shape\n",
    "    s = np.transpose(data, [0, 4, 2, 3, 1])\n",
    "    zaxis=[0, 1]\n",
    "    xaxis=[8, 4]\n",
    "    \n",
    "    print('sub the center joint #1 (spine joint in ntu and neck joint in kinetics)')\n",
    "    for i_s, skeleton in enumerate(tqdm(s)):\n",
    "        if skeleton.sum() == 0:\n",
    "            continue\n",
    "        main_body_center = skeleton[0][:, 1:2, :].copy()\n",
    "        for i_p, person in enumerate(skeleton):\n",
    "            if person.sum() == 0:\n",
    "                continue\n",
    "            mask = (person.sum(-1) != 0).reshape(T, V, 1)\n",
    "            s[i_s, i_p] = (s[i_s, i_p] - main_body_center) * mask\n",
    "\n",
    "    print('parallel the bone between hip(jpt 0) and spine(jpt 1) of the first person to the z axis')\n",
    "    for i_s, skeleton in enumerate(tqdm(s)):\n",
    "        if skeleton.sum() == 0:\n",
    "            continue\n",
    "        joint_bottom = skeleton[0, 0, zaxis[0]]\n",
    "        joint_top = skeleton[0, 0, zaxis[1]]\n",
    "        axis = np.cross(joint_top - joint_bottom, [0, 0, 1])\n",
    "        angle = angle_between(joint_top - joint_bottom, [0, 0, 1])\n",
    "        matrix_z = rotation_matrix(axis, angle)\n",
    "        for i_p, person in enumerate(skeleton):\n",
    "            if person.sum() == 0:\n",
    "                continue\n",
    "            for i_f, frame in enumerate(person):\n",
    "                if frame.sum() == 0:\n",
    "                    continue\n",
    "                for i_j, joint in enumerate(frame):\n",
    "                    s[i_s, i_p, i_f, i_j] = np.dot(matrix_z, joint)\n",
    "\n",
    "    print('parallel the bone between right shoulder(jpt 8) and left shoulder(jpt 4) of the first person to the x axis')\n",
    "    for i_s, skeleton in enumerate(tqdm(s)):\n",
    "        if skeleton.sum() == 0:\n",
    "            continue\n",
    "        joint_rshoulder = skeleton[0, 0, xaxis[0]]\n",
    "        joint_lshoulder = skeleton[0, 0, xaxis[1]]\n",
    "        axis = np.cross(joint_rshoulder - joint_lshoulder, [1, 0, 0])\n",
    "        angle = angle_between(joint_rshoulder - joint_lshoulder, [1, 0, 0])\n",
    "        matrix_x = rotation_matrix(axis, angle)\n",
    "        for i_p, person in enumerate(skeleton):\n",
    "            if person.sum() == 0:\n",
    "                continue\n",
    "            for i_f, frame in enumerate(person):\n",
    "                if frame.sum() == 0:\n",
    "                    continue\n",
    "                for i_j, joint in enumerate(frame):\n",
    "                    s[i_s, i_p, i_f, i_j] = np.dot(matrix_x, joint)\n",
    "\n",
    "    data = np.transpose(s, [0, 4, 2, 3, 1])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.set_index(X.columns[0])\n",
    "X_test = X_test.set_index(X_test.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36972512 0.46423836 0.45197736 ... 0.48315768 0.54534249 0.41140175]\n",
      " [0.36430274 0.47990098 0.44385236 ... 0.49498812 0.55907656 0.39107712]\n",
      " [0.3644477  0.47518026 0.44947845 ... 0.47587249 0.54689263 0.41249393]\n",
      " ...\n",
      " [0.36607141 0.46506559 0.44994043 ... 0.47700852 0.54728341 0.41297345]\n",
      " [0.33113919 0.47240617 0.45907522 ... 0.47906649 0.54530576 0.4114598 ]\n",
      " [0.35829733 0.45490355 0.45376928 ... 0.48152269 0.54302455 0.41521557]]\n"
     ]
    }
   ],
   "source": [
    "# Stratified Train test split\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=None)\n",
    "# for train_index, test_index in sss.split(X, y):\n",
    "#     # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9738, 960)\n",
      "           1         2         3         4         5         6         7    \\\n",
      "0     0.664990  8.281700 -8.233900  2.836300  0.726250 -8.756900  2.816100   \n",
      "1     3.152600  5.658800 -5.308100  0.906680  1.839900 -1.142000  0.068144   \n",
      "2     0.214580  0.213840  0.448330  0.612020 -0.183610 -1.238100  0.946790   \n",
      "3    -1.231100  0.864210 -1.195000 -0.058271  0.194510 -1.226100  2.572100   \n",
      "4    -4.428600  1.600500  3.878700 -3.326700  0.395380  2.778200 -0.476150   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9733 -4.674279  2.846192  2.055779 -2.729477  1.243629  0.568159 -0.730997   \n",
      "9734  0.649517  0.083739  0.136029  0.144591  0.125503  0.110201 -0.063861   \n",
      "9735  0.407259 -0.422372 -1.025572  0.005737 -0.061827 -0.531023 -0.177910   \n",
      "9736  4.319241  0.685799 -4.507963  2.383071 -0.031029 -1.438841  2.184464   \n",
      "9737 -1.111130  2.618608  3.086240 -1.141605  1.039245  1.258491 -0.204943   \n",
      "\n",
      "           8         9          10   ...        951        952        953  \\\n",
      "0    -4.258100 -8.263800   3.848700  ... -19.634000  12.600000  -2.510500   \n",
      "1     0.797650  1.745200  15.724000  ... -33.813000   4.255100   4.811000   \n",
      "2    -1.833900 -3.521000  -1.384800  ...  -1.011700 -11.427000  11.432000   \n",
      "3    -0.335670 -1.173600  -0.253600  ...   5.034300   1.126000  -5.350200   \n",
      "4    -0.780230  1.649000  14.006000  ...   8.645100   7.519300   2.444600   \n",
      "...        ...       ...        ...  ...        ...        ...        ...   \n",
      "9733  0.284407 -0.527062 -21.269861  ...   5.885233   6.204610 -15.039025   \n",
      "9734  0.145667  0.332510   0.910554  ...  -1.652463  -2.294449  -0.488706   \n",
      "9735  0.085245 -0.159297   0.369297  ...  -8.720978  -3.362489  -1.389287   \n",
      "9736 -1.679737  1.048335   1.536108  ...   4.315471   1.161927  29.829828   \n",
      "9737 -0.004981 -0.164981 -17.628358  ...   5.678516  -4.422067   1.873030   \n",
      "\n",
      "            954        955        956        957        958        959  \\\n",
      "0    -18.800000   1.363600   3.070900 -13.154000   3.058200   4.979200   \n",
      "1    -14.339000   2.890700  -6.208300  -0.348610   4.308900 -12.672000   \n",
      "2     28.413000   3.483400   7.747600  -3.940500   8.468000   5.819400   \n",
      "3     -0.946280  -5.670300 -11.158000   5.128600  -2.781400 -13.891000   \n",
      "4      2.165800   1.807700  -1.222000   2.445300  12.781000  -4.513600   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "9733 -28.304509  13.170476  -6.868676  -6.917453  13.541494  -7.888745   \n",
      "9734   1.945832  -0.916666   3.002608   2.241166  -0.381521   2.449729   \n",
      "9735  -0.269835  -0.188138  -6.133657  -1.673009  -1.063781  -4.906944   \n",
      "9736  75.543858  27.136190  28.625024  37.755864  44.031760  30.644990   \n",
      "9737   8.682241   0.451081   4.305819   2.450487  -3.547288   6.990836   \n",
      "\n",
      "            960  \n",
      "0    -18.380000  \n",
      "1    -12.786000  \n",
      "2      0.083324  \n",
      "3     -2.624600  \n",
      "4     -4.116800  \n",
      "...         ...  \n",
      "9733   0.173599  \n",
      "9734   1.634938  \n",
      "9735  -7.193841  \n",
      "9736  10.371313  \n",
      "9737  -0.783495  \n",
      "\n",
      "[9738 rows x 960 columns]\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "x_smote, y_smote = smote.fit_resample(X, y)\n",
    "# # fit predictor and target variable\n",
    "\n",
    "# Try these below instead --- Jin Hong\n",
    "#x_smote, y_smote = X_train, y\n",
    "#x_smote, y_smote = SMOTE().fit_resample(X_train, y)\n",
    "#x_smote, y_smote = SMOTETomek(random_state=42).fit_resample(X_train, y)\n",
    "#x_smote, y_smote = SMOTEENN(random_state=42).fit_resample(X_train, y)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------ Divider ------------------------------#\n",
    "# ------------- Manual downsample + SMOTETomek ------------------#\n",
    "\n",
    "# strategy = Counter(y)\n",
    "# for key, val in strategy.items():\n",
    "#     if key < 11:\n",
    "#         strategy[key] = 200\n",
    "        \n",
    "#     else:\n",
    "#         strategy[key] = val\n",
    "\n",
    "# x_rus, y_rus = RandomUnderSampler(sampling_strategy=strategy).fit_resample(X_train, y)\n",
    "# x_smote, y_smote = SMOTETomek(sampling_strategy='all').fit_resample(x_rus, y_rus)\n",
    "\n",
    "pyplot.bar(Counter(y_smote).keys(), Counter(y_smote).values())\n",
    "pyplot.show()\n",
    "\n",
    "print(x_smote.shape)\n",
    "print(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9738\n"
     ]
    }
   ],
   "source": [
    "fp = np.zeros((len(x_smote), NUM_FEATURES, NUM_FRAMES, NUM_JOINTS, 1), dtype=np.float32) #construct a matrix, with num of data, num of features for each joint, num of frames, num of joints, num of people(always 1 in our case)\n",
    "print(len(x_smote))\n",
    "for i, row in enumerate(x_smote.to_numpy()):\n",
    "    data, label = read_xyz(row)\n",
    "    fp[i, :, :, :, 0] = data\n",
    "#fp = normalisation(fp)\n",
    "np.save('train_smote_custom.npy', fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, row in enumerate(y_smote.values):\n",
    "    labels.append(row)\n",
    "with open('label_smote_custom.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = np.zeros((len(X_test), NUM_FEATURES, NUM_FRAMES, NUM_JOINTS, 1), dtype=np.float32) #construct a matrix, with num of data, num of features for each joint, num of frames, num of joints, num of people(always 1 in our case)\n",
    "for i, row in enumerate(X_test):\n",
    "    data, label = read_xyz(row)\n",
    "    fp[i, :, :, :, 0] = data\n",
    "#fp = normalisation(fp)\n",
    "np.save('test_minmax.npy', fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, row in enumerate(X_test_index):\n",
    "    labels.append(row-1)\n",
    "with open('label_test.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = np.zeros((len(dtf), NUM_FEATURES, NUM_FRAMES, NUM_JOINTS, 1), dtype=np.float32)\n",
    "#     #construct a matrix, with num of data, num of features for each joint, num of frames, num of joints, num of people(always 1 in our case)\n",
    "# with open(FILE_NAME, 'r') as f:\n",
    "#         csv_reader = reader(f)\n",
    "#         labels = []\n",
    "#         for i, row in enumerate(csv_reader):\n",
    "#             data, label = read_xyz(row)\n",
    "#             labels.append(int(label))\n",
    "#             fp[i, :, :, :, 0] = data\n",
    "#fp = normalisation(fp)\n",
    "#np.save('train_data.npy', fp)\n",
    "#np.save('test_data.npy', fp)\n",
    "\n",
    "# with open('label.pkl', 'wb') as f:\n",
    "#     pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickled_df = pd.read_pickle(\"label_smote_custom.pkl\")\n",
    "unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
